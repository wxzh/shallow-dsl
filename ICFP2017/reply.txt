We thank all the reviewers for their constructive comments.

Review A
===

- Missing comparison with Object Algebras.

A common advice on writing functional pearls is:

"no long lists of references and related work"
(in http://icfp06.cs.uchicago.edu/bird-talk.pdf)

We were following that advice!

However, we are happy to provide such comparison. Essentially our
technique and Object Algebras (OAs) can complement each other.  Our
technique is good at dealing with dependent interpretations, but
dependent interpretations create difficulties with OAs. A lot of the
follow up work on OAs is about novel (and more complex) approaches to
deal with dependencies that arize in dependent interpretations. For
example, the paper:

Feature-Oriented Programming with Object Algebras
Bruno C. d. S. Oliveira, Tijs van der Storm, Alex Loh and William R. Cook
In 27th European Conference on Object-Oriented Programming (ECOOP 2013). July 2013

describes a generalization of OAs and corresponding combinators, which
can deal with dependencies.

On the other hand, as the reviewer mentions, OAs are good for solving
the problem of how to "define and type terms in the DSL independently
of a particular interpretation of the DSL". By combining our technique
with OAs we can address the main question of the reviewer, as shown next.


- "if you support multiple interpretations, then how do I write DSL
  terms, without committing to a particular interpretation of the
  DSL?"

There are different options to build terms.

1) The approach we present in the paper allows for a weak form of
modularity, but it is not strictly speaking fully independent
from multiple interpretations.

What we can do is create smart contructors such as:

```
object Circuit1 {
  def fan(x: Int) = new Fan1 {val n=x}
  def beside(x: Circuit1, y: Circuit1) = new Beside1 {val c1=x; val c2=y}
  ...
}

object Circuit2 {
  def fan(x: Int) = new Fan2 {val n=x}
  def beside(x: Circuit2, y: Circuit2) = new Beside2 {val c1=x; val c2=y}
  ...
}
```

By switching import statements from `Circuit1` to `Circuit2`, we can
have a circuit that supports different interpretations without its
construction code being touched. However it is fair enough to say that
this is just a limited form of modularity.

2) To enable full modularity and independence from interpretations we
can employ OAs, which provide the factory methods that allow
creating terms independently of the interpretations.
A complete Scala script illustrating this alternative approach, and
using the part of the Circuit code in the paper, is available at:

https://github.com/wxzh/shallow-dsl/blob/master/src/scans/ObjectAlgebras.scala

Essentially with OAs, Object Algebra interfaces capture the abstract
signatures of the contructors:

```
trait CircuitFactory[C] {
  def fan(x: Int): C
  def beside(x: C, y: C): C
  ...
}
```

This interface can be used to construct interpretation-independent terms:

```
def mkCircuit[C](f: CircuitFactory[C]): C = f.beside(f.fan(2),f.fan(2))
```

Now, smart constructor definitions are moved into a concrete factory:

```
object Circuit1Factory extends CircuitFactory[Circuit1] {
  def fan(x: Int) = new Fan1 {val n=x}
  def beside(x: Circuit1, y: Circuit1) = new Beside1 {val c1=x; val c2=y}
  ...
}
```

Similar concrete factories can be defined for other interpretations:

```
object Circuit2Factory extends CircuitFactory[Circuit2] {
  def fan(x: Int) = new Fan2 {val n=x}
  def beside(x: Circuit2, y: Circuit2) = new Beside2 {val c1=x; val c2=y}
  ...
}
```

By supplying different concrete factories to `mkCircuit`, we obtain
circuits that models particular interpretations.

Review C
===

- "the paper doesn't acknowledge enough that the record/variant
duality"

We think we do ackowledge it, by talking about the Expression Problem
(which is essentially about such duality!). Perhaps we are taking for
granted that most readers are familiar with the Expression Problem. We
are happy to add a few explicit sentences about the duality, along the
same line of what the reviewer wrote.

- "Scala inheritance is used to save a tiny bit of redefinition"

This is an unfair view of the advantages.

* Firstly because it so happens that the code in the paper (for
obvious reasons) is minimalistic. More realistically we may have quite
a bit more code...

* Secondly, and more importantly, this misses the aspect of
  *modularity*. If we redefine, we do not get modularity, and have to
  deal with all the problems that copying&pasting code entails.

- I don't see any partial evaluation, and the implementation of joins
  is just nested loops, though the authors speculate about adding
  hash-based joins.

HashJoin is actually implemented but not shown in our paper (see
https://github.com/wxzh/shallow-dsl/blob/master/src/sql/SQLExt.scala#L31).

- "I also feel like the authors are unjustifiably hard on GADTs as a
  way to deep-embed languages."

We don't see where in the paper we make such strong criticism. Can the
reviewer be concrete about specific sentences? In all *3 occurrences*
of "algebraic datatypes" in the paper we just mention the problems of
extensibility/modularity for datatypes, which the reviewer agrees
with. We agree that GADTs are great for *deep embeddings*, so
we are happy to rephrase any awkward sentences.

- acknowledging program transformation!

The fact that shallow embeddings cannot deal with transformations is
well-known. We do *not claim* that the OO technique for shallow embeddings 
can replace deep embeddings. We merely point out that *multiple
interpretations* are possible with OO techniques, which contradicts
the commonly acknowledged single interpretation limitation of shallow
embeddings. That is the main point of the pearl and the take home
message for DSL designers!

- transformations in Rompf and Amin's work:

The SQL interpreter in the Rompf and Amin's ICFP 2015 work *does not
contain any transformations*.  Neither the original paper
(https://www.cs.purdue.edu/homes/rompf/papers/rompf-icfp15.pdf) nor
the companion code
(https://github.com/scala-lms/tutorials/tree/master/src/test/scala/lms/tutorial,
all versions prefixed by `query`) contains any transformation.  The
performance boost comes from the LMS framework and specialized data
structures. Although our approach are still applicable to the staged
versions, they are out the scope of our paper.

- "The OOP style demonstrated here forces a linearization of the method
  signatures"

No. For example, `Circuit2` shown in page 6 can be defined separately:

```
trait Circuit2 {
  def depth: Int
}
trait Identity2 extends Circuit2 {
  val n: Int
  def depth = 0
}
...
```

We can merge `Circuit1` and `Circuit2` via multiple trait inheritance:

```
trait Circuit extends Circuit1 with Circuit2
trait Identity extends Circuit12 with Identity1 with Identity2
...
```

======
Review D
======

* Using case classes for extensibility.

We are very familiar with the pattern that the reviewer points to us.
However, that pattern does not provide the solution that we are
looking for. Besides the fact that using case classes is a deep
embedding technique, the pattern does not meet our goals because:

1) If you use *sealed* classes, as the author seems to suggest
in the code:

sealed abstract class Operator

Then we cannot *modularly* extend operators: i.e. all Operators must
be defined on the same file, thus *no separate compilation* is
possible.

2) If we don't use sealed classes. That is, we use instead:

abstract class Operator

Then we are effectivelly creating partial functions that may fail at
run-time with *pattern matching failures*. This is visible in the
definition of execOp:

 def execOp(o: Operator)(yld: Record => Rep[Unit]): Rep[Unit] = o match {
       case Scan(filename, schema, fieldDelimiter, externalSchema) =>
         processCSV(filename, schema, fieldDelimiter, externalSchema)(yld)
       case Filter(pred, parent) =>
         execOp(parent) { rec => if (evalPred(pred)(rec)) yld(rec) }
       case Project(newSchema, parentSchema, parent) =>
         execOp(parent) { rec => yld(Record(rec(parentSchema), newSchema)) }
       â€¦.
   }

When we add a new case class for Join, there's no static type error
reporting that execOp needs to be extended with a new case for Join!
If the programmer *does not forget* to add that case, then
all is good. However if he does forget to add the Join case to execOp
the type system will not help!

In contrast, in our approach, if the programmer forgets to define the
case for execOp for Join, the program will not type-check.

In conclusion: case classes do not solve the Expression Problem,
whereas the approach we present does.
