\section{Related Work}

\paragraph{Deep and Shallow Embeddings}
When designing embedded DSLs, there always exists a choice between deep
embedding and shallow embedding.
However, either approach has its own strengths and weakness.
Deep embedding uses an AST to represent programs, allowing
analyses, optimizations or further translation on the programs.
Nonetheless, the AST definition is typically not extensible, as a result
adding new language constructs becomes difficult.

Shallow embedding directly encodes the source language using the semantics of
the host language bypassing an AST, which yields flexible and concise implementations.
The dual problem in shallow embedding is that the semantic domain is fixed,
making it hard to introduce new interpretations.
Although Gibbons and Wu ~\cite{gibbons} showed that it is possible to define multiple
interpretations via tuples, the encoding requires modifications on existing code.

To enjoy the benefits of both techniques, Svenningsson and Axelsson~\cite{svenningsson2012combining}
combine deep and shallow embedding together, which uses shallow embedding to
encode the surface language and translates it to a deeply embedded core language.
Similarly, \emph{Yin-Yang}~\cite{Jovanovic:2014:YCD:2658761.2658771} allows user
program written in shallow embedding and automatically generates the deeply
embedded version through Scala macros. Hofer and Ostermann~\cite{hofer2010modular} propose to provide both embedding through implementing internal and external visitor at
the same time so that clients can choose for a particular interpretation.
Scherr and Chiba~\cite{scherr2014implicit} uses \emph{implicit staging} to
extract shallow EDSL part from a normal program and represent it in a form
similar to AST, allowing optimizations to be performed.
Our approach, however, supports transformations in the first place while retaining the
simplicity of the shallow embedding.

%Hudak 1. building DSL 2. modular DSL

% Our approach. The simplicity . The AST is preserved, allowing transformations

\paragraph{Modularity of DSLs}
How to add variants (language constructs) as well as operations
(interpretations) modularly, a.k.a the Expression Problem (EP), is a hot research
topic. There are many solutions to EP. We discuss some of them in
OOP and in FP respectively.

In OOP, the Vistor pattern is widely used for modeling languages, which is
well-known for adding new operations easily. Many works
have been done for making it possible to extend variants~\cite{oliveira07genericity,oliveira09modular}.
%In fact, the Visitor pattern has a strong connection with deep and shallow embedding.
% Specifically, the internal variant corresponds to shallow embedding whereas the external variant is equivalent to deep embedding.
Object Algebras~\cite{bruno12oa} simplifies the solution, which is an variant of
internal visitor pattern.
 % However, this approach requires heavy encoding and advanced type system features in Scala.
Another line of work is on OO decomposition. ~\cite{zenger05independentlyextensible} capture recursive
arguments using virtual types with bounds using Scala. Wang and Oliveira~\cite{eptrivially16}
use covariant type refinements, a common feature available in conventional OO
languages, to solve the EP, which is the basis of our approach.
Compared to the Visitor pattern, the OO decomposition approach is simpler and
our encoding is based on ~\cite{eptrivially16}. The
naming problem for extensions is solved by family polymorphism.

In FP, the two main solutions are \emph{finally
  tagless}~\cite{carette2009finally} and \emph{data types a la
  carte}~\cite{swierstra2008data} (DTC).
Finally tagless approach uses a type class to abstract over all interpretations
of the language. Concrete interpretations are given through creating a data type and
making it an instance of that type.
DTC represents language constructs separately and composes them together using
extensible sums. However, not like OO languages which come with subtyping, one
has to manually implement the subtyping machinery for variants.
Moreover, both DTC and finally tagless approach force dependent interpretations
to be defined along with what they depend on.
This prevents new interpretation that depend on existing interpretations from
being defined modularly.

\paragraph{Family Polymorphism}

There has been a lot of related work on family polymorphism~\cite{ernst2001family}, including various lightweight encodings~\cite{Kamina:2007:LSC:1289971.1289996,saito2007essence,igarashi2005lightweight,Kamina:2008:LDC:1449913.1449932}. In the original
paper~\cite{ernst2001family}, nested classes are represented as attributes of an object, which involves a dependent type system. In~\cite{igarashi2005lightweight}, Saito and Igarashi
proposed a lightweight variant of family polymorphism, which uses classes rather than objects to represent families. Later work in~\cite{igarashi2005lightweight}
proposes a simple extension to Featherweight Generic Java~\cite{Igarashi:2001:FJM:503502.503505}, introducing self-type variables. There are also some existing languages,
like Scala, which supports symmetric mixin compositions and self-type annotations[?], hence can provide better support for encoding family
polymorphism. Our lightweight encoding relies entirely on the existing Java language without language extensions, and certainly some features from
the original paper are sacrificed, including the mismatching problem of recursive class definitions (also known as binary methods~\cite{bruce1995binary}). Relying
on the Java semantics, covariant return types are supported and used for our automatic type refinements. Nevertheless, in the case of binary methods,
we cannot address those with recursive member types as parameters. This problem is however handled in some other work like MyType[?], ThisType[?] and self-type
annotations in Scala as we said.

On the other hand, our approach uses nested interfaces to build the relationship among families and members, which is different from
path-dependent types in~\cite{ernst2001family}. The work in~\cite{ernst2003higher} inspires us with the concept of higher-order hierarchies, and hence our \textsf{@Family} annotation
provides support for nested families. Furthermore, our lightweight encoding of family polymorphism is polished with the help of annotation processing
to generate constructor methods automatically.

%[1] family polymorphism
%[2] Lightweight scalable components
%[3] The essence of lightweight family polymorphism
%[4] Lightweight family polymorphism
%[5] Lightweight dependent classes
%[6] Featherweight Java
%[7] On binary method
%[8] Higher-order hierarchies

%\paragraph{ThisType}

\paragraph{Multiple Inheritance}

Multiple inheritance is an expressive and useful feature in programming languages, yet difficult to model in relation to the famous diamond problem[?].
Many models have been developed to integrate multiple inheritance in some languages, including C++ virtual inheritance[?], mixins[?], traits[?] and
hybrid models such as CZ[?]. In our approach, introducing new variants or operations requires subtyping relations among member types to be built, and
hence we rely on the Java multiple interface inheritance. A difference from the other models is that our \textsf{@Family} annotation can check method
typing and detect conflicts during the annotation processing, and on the other hand, subtyping relations are automatically generated for the users, which
makes client code more concise. Furthermore, we have mentioned that interfaces are updated with auto-generated constructor methods, whereas object initialization is a big problem in some other models.
