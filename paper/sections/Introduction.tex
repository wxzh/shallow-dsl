\section{Introduction}

Since Hudak's seminal paper on Embedded DSLs (EDSLs)~\cite{}, existing
languages (such as Haskell) have been used to directly encode
DSLs. Two common approaches to EDSLs are the so-called \emph{shallow}
and \emph{deep} embeddings. The origin of that terminology can be
attributed to Boulton's work~\cite{}. The difference between these
two styles of embeddings is commonly described as follows:

\begin{quote}
\emph{With a deep embedding, terms in the DSL are implemented simply to
construct an abstract syntax tree (AST), which is subsequently
transformed for optimization and traversed for evaluation. With a
shallow embedding, terms in the DSL are implemented directly by
their semantics, bypassing the intermediate AST and its traversal.}\cite{gibbons15folding}
\end{quote}

%\begin{comment}
%This definition is widely accepted and similar definitions appear in
%many other works~\cite{}. 
%We argue that this definition is vague,
%and often leads to some contradicting claims. 

Although the above definition is quite reasonable and widely accepted,
it leaves some space to (mis)interpretation. For example it is unclear 
how to classify an EDSL using the {\sc Composite} or {\sc Interpreter} 
patterns in OOP. Would this OO approach be
classified as a shallow or deep embedding? We believe arguments can be
made both ways. Since the {\sc Composite}
pattern is normally accepted to be a way to encode ASTs, it would be
reasonable to say that \emph{according to definition of deep embedding
  above, the OO approach classifies as a deep
  embedding}. However, as we shall argure in the remainder of the
paper, another possible interpretation is that the OO approach is
really a shallow embedding. At least some authors~\cite{} seem to agree with 
the latter interpretation, but we believe that the current definition
leaves some space open to interpretation.

\begin{comment}
For example, in their work
on EDSLs~\cite{}, Gibbons and Wu claim that deep embeddings (which
encode ASTs using algebraic datatypes in Haskell) allow adding new DSL
interpretations easily, but they make adding new language constructs
difficult. In contrast Gibbons and Wu claim that shallow embeddings
have dual modularity properties: new cases are easy to add, but new
interpretations are hard.  However what if, instead of using Haskell
and algebraic datatypes, one uses an OO language to encode an AST, for
example with the {\sc Composite} pattern.  Would this OO approach be
classified as a shallow or deep embedding? We believe arguments can be
made both ways. Since the {\sc Composite}
pattern is normally accepted to be a way to encode ASTs, it would be
reasonable to say that \emph{according to definition of deep embedding
  above, the OO approach classifies as a deep
  embedding}. Unfortunatelly this interpretation could be problematic.
As the Expression Problem~\cite{} tell us,
in the OO approach adding new language constructs is easy, but adding
interpretations is hard. Thus this would contradict Gibbons and Wu's
claims, since we have an AST representation (i.e. a deep embedding)
with the modularity properties of shallow embeddings.

We believe that the core of problem is that ASTs can be represented in
multiple ways. In particular, it is well know that functions alone are
enough to encode datastructures such as ASTs (via Church
encodings~\cite{}).  Distinguishing deep and shallow embeddings based
solely on whether a ``real'' datastructure is being used or not is
misleading.  Moreover, it gives the impression that shallow embeddings
are significantly less expressive than deep embeddings, because they
do not have access to the datastructure.
Gibbons and Wu themselves feel uneasy with the definition of shallow 
embeddings when they say:
``\emph{So it turns out that the syntax of the DSL is not really as ephemeral
in a shallow embedding as Boulton's choice of terms suggests.}''
\end{comment}

To avoid confusion and make the terminology more precise, we first 
propose distinguishing EDSLs in terms of the data
abstraction used to model the language constructs instead.  We follow
Reynold's classification~\cite{} of data abstractions:
\emph{procedural abstraction} and \emph{user-defined types}. It is
clear that shallow embeddings use \emph{procedural
  abstraction}~\cite{}: the DSLs are modelled by interpretation
functions. Therefore, the other implementation option for EDSLs is to use
\emph{user-defined types}. In Reynolds terminology user-defined types
mean disjoint union types, which are nowadays commonly available in
modern languages as \emph{algebraic datatypes}. Disjoint union types 
can also be emulated in OOP using the {\sc Visitor} pattern. A
distinction based on data abstraction provides a remedy for possible
misinterpretation. An EDSL implemented with algebraic
datatypes falls into the category of user-defined types (deep embedding), 
while a Composite-based OO implementation falls under procedural
abstraction (shallow embedding). For the rest of the paper we identify shallow EDSLs 
with EDSLs implemented using procedural abstraction.

This paper shows that OOP languages have
advantages for the implementation of shallow embeddings.
As Cook~\cite{} argued procedural abstraction is the essence of
Object-Oriented Programming. If we accept Cook's view, the
implementation of a shallow DSL in OOP languages should simply
correspond to a standard object-oriented program. Given
that Object-Oriented Languages have evolved over more than 50 years 
to improve the use of procedural abstraction, they ought to have some 
advantages to encode shallow EDSLs. 

We show that OOP abstractions, including \emph{inheritance}
and \emph{subtyping}, increase the modularity and reuse of shallow
DSLs when compared to classical procedural abstraction. We make this
argument by taking a recent paper by Gibbons and Wu, where procedural
abstraction is used in Haskell to model a simple EDSL, and we recode
that EDSL in Java. Although from the \emph{syntactical} point of view
there are obvious disadvantages in the Java version, from the semantic
and modularity point of view the Java version has clear advantages.


This paper has two goals:

\begin{itemize}

\item To argue that 

\end{itemize} 