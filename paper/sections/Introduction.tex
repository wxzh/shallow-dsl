\section{Introduction}

Since Hudak's seminal paper on Embedded DSLs (EDSLs)~\cite{}, existing
languages (such as Haskell) have been used to directly encode
DSLs. Two common approaches to EDSLs are the so-called \emph{shallow}
and \emph{deep} embeddings. The origin of that terminology can be
attributed to Boulton's work~\cite{}. The difference between these
two styles of embeddings is commonly described as follows:

\begin{quote}
\emph{With a deep embedding, terms in the DSL are implemented simply to
construct an abstract syntax tree (AST), which is subsequently
transformed for optimization and traversed for evaluation. With a
shallow embedding, terms in the DSL are implemented directly by
their semantics, bypassing the intermediate AST and its traversal.}\cite{gibbons15folding}
\end{quote}

%\begin{comment}
%This definition is widely accepted and similar definitions appear in
%many other works~\cite{}. 
%We argue that this definition is vague,
%and often leads to some contradicting claims. 

Although the above definition is quite reasonable and widely accepted,
it leaves some space to (mis)interpretation. For example it is unclear 
how to classify an EDSL implemented using the {\sc Composite} or {\sc Interpreter} 
patterns in OOP. Would this OO approach be
classified as a shallow or deep embedding? We believe arguments can be
made both ways. Since the {\sc Composite} or {\sc Interpreter}
patterns are normally accepted to provide a way to encode ASTs, it would be
reasonable to say that \emph{according to definition of deep embedding
  above, the OO approach classifies as a deep
  embedding}. However, as we shall argure in the remainder of the
paper, another possible interpretation is that the OO approach is
really a shallow embedding. At least some authors~\cite{} seem to
implicitly agree with 
the latter interpretation.

\begin{comment}
For example, in their work
on EDSLs~\cite{}, Gibbons and Wu claim that deep embeddings (which
encode ASTs using algebraic datatypes in Haskell) allow adding new DSL
interpretations easily, but they make adding new language constructs
difficult. In contrast Gibbons and Wu claim that shallow embeddings
have dual modularity properties: new cases are easy to add, but new
interpretations are hard.  However what if, instead of using Haskell
and algebraic datatypes, one uses an OO language to encode an AST, for
example with the {\sc Composite} pattern.  Would this OO approach be
classified as a shallow or deep embedding? We believe arguments can be
made both ways. Since the {\sc Composite}
pattern is normally accepted to be a way to encode ASTs, it would be
reasonable to say that \emph{according to definition of deep embedding
  above, the OO approach classifies as a deep
  embedding}. Unfortunatelly this interpretation could be problematic.
As the Expression Problem~\cite{} tell us,
in the OO approach adding new language constructs is easy, but adding
interpretations is hard. Thus this would contradict Gibbons and Wu's
claims, since we have an AST representation (i.e. a deep embedding)
with the modularity properties of shallow embeddings.

We believe that the core of problem is that ASTs can be represented in
multiple ways. In particular, it is well know that functions alone are
enough to encode datastructures such as ASTs (via Church
encodings~\cite{}).  Distinguishing deep and shallow embeddings based
solely on whether a ``real'' datastructure is being used or not is
misleading.  Moreover, it gives the impression that shallow embeddings
are significantly less expressive than deep embeddings, because they
do not have access to the datastructure.
Gibbons and Wu themselves feel uneasy with the definition of shallow 
embeddings when they say:
``\emph{So it turns out that the syntax of the DSL is not really as ephemeral
in a shallow embedding as Boulton's choice of terms suggests.}''
\end{comment}

To avoid confusion and make the terminology more precise,
this paper distinguishes EDSLs in terms of the data
abstraction used to model the language constructs instead.  We follow
Reynold's classification~\cite{} of data abstractions:
\emph{procedural abstraction} and \emph{user-defined types}. It is
clear that shallow embeddings use \emph{procedural
  abstraction}~\cite{}: the DSLs are modelled by interpretation
functions. Therefore, the other implementation option for EDSLs is to use
\emph{user-defined types}. In Reynolds terminology user-defined types
mean disjoint union types, which are nowadays commonly available in
modern languages as \emph{algebraic datatypes}. Disjoint union types 
can also be emulated in OOP using the {\sc Visitor} pattern. A
distinction based on data abstraction provides a remedy for possible
misinterpretation. An EDSL implemented with algebraic
datatypes falls into the category of user-defined types (deep embedding), 
while a Composite-based OO implementation falls under procedural
abstraction (shallow embedding). For the rest of the paper we identify shallow EDSLs 
with EDSLs implemented using procedural abstraction.

As Cook~\cite{} argued
procedural abstraction is the essence of Object-Oriented
Programming. If we accept Cook's view, the implementation of a shallow
DSL in OOP languages should simply correspond to a standard
object-oriented program. Given that OOP languages have
evolved over more than 50 years to improve the use of procedural
abstraction, they ought to have some advantages to encode shallow
EDSLs.

The main goal of this paper is to show that OOP languages have advantages for the
implementation of shallow embeddings.  
In order to understand how OOP can help with shallow embeddings, lets
first review some of the limitations of shallow embeddings commonly found in
the literature:

\begin{enumerate}

\item {\bf Single Interpretation} An often stated limitation of
  shallow embeddings is that they only support a single
  interpretation.

\item {\bf No Transformations} Another commonly stated limitation 
of shallow embeddings is that they do not support transformations,
preventing optimizations and other useful transformations.

\end{enumerate}

\noindent Both limitations are often used as motivators to switch to deep embeddings.

We show that OOP abstractions, including \emph{(multiple)
  inheritance}, \emph{subtyping} and \emph{type-refinement}, are
helpful to address those problems. For the first problem, we can
employ a recently proposed design pattern~\cite{}, which provides a simple
solution to the \emph{Expression Problem}\cite{} in OOP languages. Thus
using just standard OOP mechanims enables \emph{multiple modular
  interpretations} to co-exist and be combined in shallow embeddings.
For the second problem, we show that transformations can be encoded 
with recursive objects. Interestingly enough, for transformations it
is possible to port back the OO solution to Haskell. 

We make our arguments by taking a recent paper by Gibbons and Wu,
where procedural abstraction is used in Haskell to model a simple
EDSL, and we recode that EDSL in Scala. Although from the
\emph{syntactical} point of view there are minor inconveniences in
the Scala version, from the \emph{semantic} and \emph{modularity} point of view the
Scala version has clear advantages.

In summary, our contributions are:

\begin{itemize}

\item {\bf Multiple Modular Interpretations for Shallow Embeddings:} 
  We show that with standard OOP mechanisms it is easy to support multiple modular
  interpretations for shallow embeddings.

\item {\bf Transformations for Shallow Embeddings:} We show that
  transformations are encodable with recursive objects. Moreover, this technique
  can be ported back into functional programming as well.

\end{itemize}